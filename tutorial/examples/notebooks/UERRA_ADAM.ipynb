{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using ADAM-API to access UERRA regional reanalysis\n",
    "\n",
    "- you need to get an account to https://reliance.adamplatform.eu/ (use ORCID to authenticate) and key your ADAM API key\n",
    "- make sure you save your ADAM API key in a file `$HOME/adam-key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install adamapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import zipfile\n",
    "import adamapi as adam\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import cartopy.crs as ccrs\n",
    "from cmcrameri import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_key = open(os.path.join(os.environ[\"HOME\"], \"adam-key\")).read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = adam.Auth()\n",
    "\n",
    "a.setKey(adam_key)\n",
    "a.setAdamCore(\"https://reliance.adamplatform.eu\")\n",
    "a.authorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Discover UERRA datasets \n",
    "- This step is useful to get the dataset identifier (unique for a given datacube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discoverDasasets(a, search_name):\n",
    "    datasets = adam.Datasets(a)\n",
    "    catalogue = datasets.getDatasets()\n",
    "    # Extracting the size of the catalogue\n",
    "    total = catalogue[\"properties\"][\"totalResults\"]\n",
    "    items = catalogue[\"properties\"][\"itemsPerPage\"]\n",
    "    pages = total // items\n",
    "\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"\\033[1m\" + \"List of available datasets:\")\n",
    "    print(\"\\033[0m\")\n",
    "\n",
    "    # Extracting the list of datasets across the whole catalogue\n",
    "    for i in range(0, pages):\n",
    "        page = datasets.getDatasets(page=i)\n",
    "        for element in page[\"content\"]:\n",
    "            if search_name in element[\"title\"]:\n",
    "                print(\n",
    "                    element[\"title\"]\n",
    "                    + \"\\033[1m\"\n",
    "                    + \" --> datasetId \"\n",
    "                    + \"\\033[0m\"\n",
    "                    + \"= \"\n",
    "                    + element[\"datasetId\"]\n",
    "                )\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = discoverDasasets(a, \"UERRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Get metadata from Snow density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetID = \"71100:UERRA_SNOW_DENSITY\"\n",
    "\n",
    "print(\"\\033[1;34m\" + \"Metadata of \" + datasetID + \":\")\n",
    "print(\"\\033[0;0m\")\n",
    "\n",
    "paged = datasets.getDatasets(datasetID)\n",
    "for i in paged.items():\n",
    "    print(\"\\033[1m\" + str(i[0]) + \"\\033[0m\" + \": \" + str(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Discover and select products from a dataset\n",
    "- for a given time range and spatial coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Get data over the Nordics countries\n",
    "- The geometry field is extracted from a GeoJSON object , retrieving the value of the \"feature\" element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Search data\n",
    "- only print the first 10 products\n",
    "- UERRA reanalysis are provided 4 times a day (00, 06, 12, 18 UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geojson_rewind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamapi import Search\n",
    "from geojson_rewind import rewind\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The GeoJson object needs to be rearranged according to the counterclockwise winding order.This operation is executed in the next few lines to obtain a geometry that meets the requirements of the method. Geom_1 is the final result to be used in the discovery operation.\n",
    "- you can go to https://geojson.io/ to draw an area of interest (save the produced geojson to a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nordics.geojson\") as f:\n",
    "    geom_dict = json.load(f)\n",
    "output = rewind(geom_dict)\n",
    "geom_1 = str(geom_dict[\"features\"][0][\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2015-01-01T00:00:00Z\"\n",
    "end_date = \"2015-12-31T00:00:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = Search(a)\n",
    "results = search.getProducts(\n",
    "    datasetID, geometry=geom_1, startDate=start_date, endDate=end_date\n",
    ")\n",
    "\n",
    "# Printing the results\n",
    "\n",
    "print(\"\\033[1m\" + \"List of available products:\")\n",
    "print(\"\\033[0m\")\n",
    "count = 1\n",
    "for i in results[\"content\"]:\n",
    "\n",
    "    print(\"\\033[1;31;1m\" + \"#\" + str(count))\n",
    "    print(\"\\033[0m\")\n",
    "    for k in i.items():\n",
    "        print(str(k[0]) + \": \" + str(k[1]))\n",
    "    count = count + 1\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Get data\n",
    "- be aware that you alwasy get daily average from ADAM-API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZipData(auth, dataset_info):\n",
    "    if not (\n",
    "        pathlib.Path(pathlib.Path(dataset_info[\"outputFname\"]).stem).exists()\n",
    "        or pathlib.Path(dataset_info[\"outputFname\"]).exists()\n",
    "    ):\n",
    "        data = adam.GetData(auth)\n",
    "        image = data.getData(\n",
    "            datasetId=dataset_info[\"datasetID\"],\n",
    "            startDate=dataset_info[\"startDate\"],\n",
    "            endDate=dataset_info[\"endDate\"],\n",
    "            geometry=dataset_info[\"geometry\"],\n",
    "            outputFname=dataset_info[\"outputFname\"],\n",
    "        )\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output_file = \"./UERRA_SNOW_DENSITY_SWE_ADAMAPI_\" + start_date + \"-\" + end_date + \".zip\"\n",
    "\n",
    "datasetInfo = {\n",
    "    \"datasetID\": datasetID,\n",
    "    \"startDate\": start_date,\n",
    "    \"endDate\": end_date,\n",
    "    \"geometry\": geom_1,\n",
    "    \"outputFname\": output_file,\n",
    "}\n",
    "getZipData(a, datasetInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Data analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Unzip data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipData(filename):\n",
    "    with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path=pathlib.Path(filename).stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pathlib.Path(pathlib.Path(output_file).stem).exists():\n",
    "    unzipData(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Read data in xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_datetimeindex(paths):\n",
    "    return [\n",
    "        datetime.strptime(date.split(\"_\")[-1].split(\".\")[0], \"%Y-%m-%dt%f\")\n",
    "        for date in paths\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dirtif, varname):\n",
    "    geotiff_list = glob.glob(dirtif)\n",
    "    # Create variable used for time axis\n",
    "    time_var = xr.Variable(\"time\", paths_to_datetimeindex(geotiff_list))\n",
    "    # Load in and concatenate all individual GeoTIFFs\n",
    "    geotiffs_da = xr.concat(\n",
    "        [xr.open_rasterio(i, parse_coordinates=True) for i in geotiff_list],\n",
    "        dim=time_var,\n",
    "    )\n",
    "    # Covert our xarray.DataArray into a xarray.Dataset\n",
    "    geotiffs_da = geotiffs_da.to_dataset(\"band\")\n",
    "    # Rename the dimensions to make it CF-convention compliant\n",
    "    geotiffs_da = geotiffs_da.rename_dims({\"y\": \"latitude\", \"x\": \"longitude\"})\n",
    "    # Rename the variable to a more useful name\n",
    "    geotiffs_da = geotiffs_da.rename_vars(\n",
    "        {1: varname, \"y\": \"latitude\", \"x\": \"longitude\"}\n",
    "    )\n",
    "    # set attribute to variable\n",
    "    geotiffs_da[varname].attrs = {\n",
    "        \"units\": geotiffs_da.attrs[varname + \"#units\"],\n",
    "        \"long_name\": geotiffs_da.attrs[varname + \"#long_name\"],\n",
    "    }\n",
    "    return geotiffs_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = os.path.join(pathlib.Path(output_file).stem, \"*.tif\")\n",
    "geotiff_ds = getData(path_files, \"rsn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geotiff_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "- generate seasonal average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_dm = geotiff_ds.groupby(\"time.season\").mean(\n",
    "    \"time\", keep_attrs=True, skipna=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_plot = ccrs.Mercator()\n",
    "\n",
    "p = geotiff_dm[\"rsn\"].plot(\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    aspect=geotiff_dm.dims[\"longitude\"]\n",
    "    / geotiff_dm.dims[\"latitude\"],  # for a sensible figsize\n",
    "    subplot_kws={\"projection\": proj_plot},\n",
    "    col=\"season\",\n",
    "    col_wrap=2,\n",
    "    robust=True,\n",
    "    cmap=cm.devon_r,\n",
    ")\n",
    "# We have to set the map's options on all four axes\n",
    "for ax, i in zip(p.axes.flat, geotiff_dm.season.values):\n",
    "    ax.coastlines()\n",
    "    ax.set_title(\"Season \" + i, fontsize=18)\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(15.0, 15.0)\n",
    "fig.savefig(\"UERRA_rsn.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
