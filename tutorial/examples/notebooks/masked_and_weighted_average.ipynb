{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using masks and computing weighted average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is based from xarray example http://xarray.pydata.org/en/stable/examples/area_weighted_temperature.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "xr.set_options(display_style=\"html\")\n",
    "import intake\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "col = intake.open_esm_datastore(cat_url)\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = col.search(\n",
    "    source_id=[\"NorESM2-LM\"],\n",
    "    experiment_id=[\"historical\"],\n",
    "    table_id=[\"Amon\"],\n",
    "    variable_id=[\"tas\"],\n",
    "    member_id=[\"r1i1p1f1\"],\n",
    ")\n",
    "cat.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary from the list of datasets we found\n",
    "- This step may take several minutes so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = cat.to_dataset_dict(zarr_kwargs={\"use_cftime\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset_dict[list(dset_dict.keys())[0]]\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mercator(central_longitude=-10)\n",
    "\n",
    "f, ax = plt.subplots(subplot_kw=dict(projection=projection))\n",
    "\n",
    "dset[\"tas\"].isel(time=0).plot(\n",
    "    transform=ccrs.PlateCarree(), cbar_kwargs=dict(shrink=0.7), cmap=\"coolwarm\"\n",
    ")\n",
    "ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute weighted mean\n",
    "\n",
    "1. Creating weights: for a rectangular grid the cosine of the latitude is proportional to the grid cell area.\n",
    "2. Compute weighted mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeWeightedMean(ds):\n",
    "    # Compute weights based on the xarray you pass\n",
    "    weights = np.cos(np.deg2rad(ds.lat))\n",
    "    weights.name = \"weights\"\n",
    "    # Compute weighted mean\n",
    "    air_weighted = ds.weighted(weights)\n",
    "    weighted_mean = air_weighted.mean((\"lon\", \"lat\"))\n",
    "    return weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute weighted average over the entire globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean = computeWeightedMean(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with unweighted mean\n",
    "- We select a time range\n",
    "- Note how the weighted mean temperature is higher than the unweighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean[\"tas\"].sel(time=slice(\"2000-01-01\", \"2010-01-01\")).plot(label=\"weighted\")\n",
    "dset[\"tas\"].sel(time=slice(\"2000-01-01\", \"2010-01-01\")).mean((\"lon\", \"lat\")).plot(\n",
    "    label=\"unweighted\"\n",
    ")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Weigted arctic average\n",
    "Let's try to also take only the data above 60$^\\circ$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean = computeWeightedMean(dset.where(dset[\"lat\"] > 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean[\"tas\"].sel(time=slice(\"2000-01-01\", \"2010-01-01\")).plot(label=\"weighted\")\n",
    "dset[\"tas\"].where(dset[\"lat\"] > 60.0).sel(time=slice(\"2000-01-01\", \"2010-01-01\")).mean(\n",
    "    (\"lon\", \"lat\")\n",
    ").plot(label=\"unweighted\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
